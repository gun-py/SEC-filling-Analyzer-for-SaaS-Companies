{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bTesUT6-7kV"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scraper.web_scraper import FinancialStatements, Attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32ZnhSJv0KMU"
      },
      "outputs": [],
      "source": [
        "cik = '1786352'\n",
        "form = '10-k'\n",
        "def download_xml(cik, form):\n",
        "    base = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type={}&dateb=&owner=include&count=100&search_text='.format(cik, form)\n",
        "    heads = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
        "\n",
        "    content = requests.get(base, headers = heads)\n",
        "    bs4_base = BeautifulSoup(content.text)\n",
        "    years = 0\n",
        "\n",
        "    path_dict = {}\n",
        "    if not os.path.exists(cik):\n",
        "        os.makedirs(cik)\n",
        "\n",
        "    for hrefs in bs4_base.find_all('a', href=True):\n",
        "\n",
        "        if hrefs['href'].split('.')[-1] == 'htm' and len(hrefs['href'].split('/')) == 7:\n",
        "            if hrefs.parent.parent.td.get_text().lower() != '10-k':\n",
        "                continue\n",
        "            years += 1\n",
        "            htm_url = 'https://www.sec.gov/' + hrefs['href']\n",
        "            content = requests.get(htm_url, headers = heads)\n",
        "            bs4_htm = BeautifulSoup(content.text)\n",
        "\n",
        "            for htm_hrefs in bs4_htm.find_all('a', href=True):\n",
        "                if htm_hrefs['href'].split('.')[-1] == 'xml':\n",
        "                    x = htm_hrefs['href'].split('.')[-2].split('_')[-1]\n",
        "                    if x == 'cal':\n",
        "                        y = htm_hrefs['href'].split('/')[-1]\n",
        "                        z = y.split('-')[1][:8]\n",
        "                        path_dict[z] = {'cal':'', 'lab':'', 'htm':''}\n",
        "                        break\n",
        "\n",
        "            for htm_hrefs in bs4_htm.find_all('a', href=True):\n",
        "                if htm_hrefs['href'].split('.')[-1] == 'xml':\n",
        "                    if '_' not in htm_hrefs['href'].split('/')[-1]:\n",
        "                        x = 'htm'\n",
        "                    else:\n",
        "                        x = htm_hrefs['href'].split('.')[-2].split('_')[-1]\n",
        "\n",
        "                    if x == 'cal' or x == 'lab' or x == 'htm':\n",
        "                        url = 'https://www.sec.gov/' + htm_hrefs['href']\n",
        "                        bs4_end = BeautifulSoup(requests.get(url, headers = heads).text)\n",
        "                        y = url.split('/')[-1]\n",
        "                        \n",
        "                        file_path = cik + '/' + y\n",
        "                        path_dict[z][x] = file_path\n",
        "                        f =  open(file_path, \"w\")\n",
        "                        f.write(str(bs4_end))\n",
        "                        f.close()\n",
        "        if years >= 1:\n",
        "            break\n",
        "\n",
        "    return path_dict\n",
        "\n",
        "try:\n",
        "    path_dict = download_xml(cik, form)\n",
        "except:\n",
        "    print(\"bleh\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLJViIgS_mu-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('base_comp_cik2.csv')\n",
        "df = df[df['CIK'].isna() == False]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_paths = {}\n",
        "fin_count = 0\n",
        "attrib_count = 0\n",
        "for i in df.index:\n",
        "    cik = str(int(df.iloc[i]['CIK']))\n",
        "    try:\n",
        "        path_dict = download_xml(cik, form)\n",
        "        all_paths[cik] = path_dict\n",
        "        year = list(path_dict.keys())[0]\n",
        "        calculation_file = path_dict[year]['cal']\n",
        "        label_file = path_dict[year]['lab']\n",
        "        extracted_file = path_dict[year]['htm']\n",
        "        \n",
        "        try:\n",
        "            x = FinancialStatements(calculation_file, extracted_file)\n",
        "            if x.financial_statements != {}:\n",
        "                x.save_json('financial_statements/'+cik+'.json')\n",
        "                fin_count+=1\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            x = Attributes(label_file, extracted_file)\n",
        "            if x.attributes != {}:\n",
        "                x.save_json('attributes/'+cik+'.json')\n",
        "                attrib_count+=1\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "    print(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_json = json.dumps(all_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('path_json', 'w') as f:\n",
        "    f.write(path_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Get XLMs from CIK.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
